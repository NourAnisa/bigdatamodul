# -*- coding: utf-8 -*-
"""Sentiment_Data_Analysis_PUBG_Mobile_App.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YyNOpJAukfXGAxUxF7mhVmqi3MZ9eIn_

**Sentimen Analisis Aplikasi PUBG Mobile di play store**
"""

!pip install google-play-scraper
!pip install emoji

from google_play_scraper import Sort, reviews
from google_play_scraper import app
import pandas as pd
import numpy as np
import emoji
import re
@app.route('/')
def home():
    @app.route('/analyze', methods=['POST'])
def analyze():

    if not app_id:
        return jsonify({'error': 'No app ID provided'}), 400

app_id = request.form['app_id']
result, continuation_token = reviews(
    app_id,
    lang='id', #bahasa
    country='id', #negara
    sort=Sort.MOST_RELEVANT, #sorting yang paling relevan
    count=1000, #jumlah dataset
    filter_score_with= None
)

# Dataframe dengan nama
data = pd.DataFrame(np.array(result),columns=['review'])
data = data.join(pd.DataFrame(data.pop('review').tolist()))
data.head()

# @title score

from matplotlib import pyplot as plt
data['score'].plot(kind='hist', bins=20, title='score')
plt.gca().spines[['top', 'right',]].set_visible(False)

len(data)

data = data[['content','score']]
data.head()

data = data.rename(columns={'content': 'komentar','score': 'value'}) #mengganti nama fitur
data.head()

data.to_csv("komentar pubgm 1000 Data.csv", index = False , encoding='utf-8')

dataPubgm = pd.read_csv('/content/komentar pubgm 1000 Data.csv')
dataPubgm.head()

"""SCRAPING DATA"""

df = pd.read_csv('/content/komentar pubgm 1000 Data.csv')

df.head(10)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from wordcloud import WordCloud

data = pd.read_csv('/content/komentar pubgm 1000 Data.csv')

data.head()

# menghilangkan baris yang memiliki nilai null/kosong
data = data.dropna()

# menghilangkan tanda baca dan karakter khusus
data['clean_text'] = data['komentar'].str.replace('[^\w\s]', '')

# mengubah teks menjadi huruf kecil
data['clean_text'] = data['clean_text'].str.lower()

#menghilangkan URL
data['clean_text'] = data['clean_text'].apply(lambda x: re.sub(r'http\S+', '', x))

# menghilangkan stop words (kata umum yang tidak memberikan informasi tambahan)
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))
data['clean_text'] = data['clean_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))

# menggabungkan semua komentar menjadi satu teks
all_text = ' '.join(data['clean_text'])

# membuat word cloud
wordcloud = WordCloud(width=1000, height=500, max_font_size=150, random_state=42).generate(all_text)

# menampilkan Word Cloud
plt.figure(figsize=(10, 6))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()

import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')

stop_words = set(stopwords.words('indonesian'))
stop_words.update(['dan', 'yang', 'lalu', 'yg', 'gk', 'saya', 'lagi'])

data['clean_text'] = data['komentar'].str.replace('[^\w\s]', '')
data['clean_text'] = data['clean_text'].str.lower()
data['clean_text'] = data['clean_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))

all_text = ' '.join(data['clean_text'])

wordcloud = WordCloud(width=1000, height=500, max_font_size=150, random_state=42).generate(all_text)

plt.figure(figsize=(10, 6))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()

"""Melakukan Sentimental Analisis"""

import nltk
nltk.download('vader_lexicon')

from nltk.sentiment import SentimentIntensityAnalyzer

# menginisialisasi SentimentIntensityAnalyzer
sia = SentimentIntensityAnalyzer()

# menghitung snetimen untuk setiap komentar
data['sentiment'] = data['clean_text'].apply(lambda x: sia.polarity_scores(x)['compound'])

# melabeli sentimen (misal 'positif' , 'negatif' , 'netral') berdasarkan nilai sentimen
data['sentiment_label'] = data['sentiment'].apply(lambda x: 'positif' if x > 0 else ('negatif' if x < 0 else 'netral'))

# menampilkan beberapa komentar dan sentimen terkait
data[['komentar', 'sentiment_label']].head(10)

from matplotlib import pyplot as plt
import seaborn as sns
_df_0.groupby('sentiment_label').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))
plt.gca().spines[['top', 'right',]].set_visible(False)

data.to_csv("/content//hasil komentar pubgm 1000 Data.csv", index = False , encoding='utf-8')